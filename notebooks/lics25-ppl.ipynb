{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/gbdrt/mu-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_ppl import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LICS 2025 - Tutorial on Linear Logic and Probabilistic Programming](https://lics.siglog.org/lics25/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic programs represent random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice() -> int:\n",
    "    a = sample(RandInt(1, 6), name=\"a\")\n",
    "    b = sample(RandInt(1, 6), name=\"b\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the experiment representing the random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The law of the random variable can be computed by an inference algorithm. \n",
    "\n",
    "For instance the enumeration algorithm for discrete distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Enumeration():\n",
    "    dist: Categorical[int] = infer(dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sample of the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the statistics of the distribution  and vizualize its mass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = dist.stats()\n",
    "print(\"mean: \",s[0], \"\\nstandard deviation: \", s[1])\n",
    "viz(dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions on a Bayesian Networks can be modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wet() -> bool:\n",
    "    cloudy = sample(Bernoulli(0.5), name=\"cloudy\")\n",
    "    \n",
    "    p_sprinkle, p_rain = (0.1, 0.8) if cloudy else (0.5, 0.2)\n",
    "    sprinkle = sample(Bernoulli(p_sprinkle), name=\"sprinkle\")\n",
    "    rain = sample(Bernoulli(p_rain), name=\"rain\")\n",
    "        \n",
    "    p_wet = 0.99 if (sprinkle and rain) else 0.9 if (sprinkle != rain) else 0\n",
    "    wet = sample(Bernoulli(p_wet), name=\"wet\")\n",
    "    assume(rain)\n",
    "    return wet\n",
    "\n",
    "with Enumeration():\n",
    "    dist: Categorical[bool] = infer(wet)  \n",
    "    print(dist.stats())\n",
    "    viz(dist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some programs need streams of i.i.d. copies of a random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoppingTime(d) -> int:\n",
    "    time = 1\n",
    "    while sample(d):\n",
    "        time = time +1\n",
    "    return time\n",
    "    \n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    ST: Categorical[float] = infer(StoppingTime, Bernoulli(0.7))  \n",
    "    print(ST.stats())\n",
    "    viz(ST)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FairCoin(d) -> bool:\n",
    "    a = sample(d)\n",
    "    b = sample(d)\n",
    "    if (a and not b):\n",
    "        return True\n",
    "    elif (b and not a):\n",
    "        return False\n",
    "    else:\n",
    "        return FairCoin(d)\n",
    "\n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    FC: Categorical[bool] = infer(FairCoin, Bernoulli(0.3))\n",
    "    print(FC.stats())\n",
    "    viz(FC)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning can be hard: `assume(d2<1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def HardDisk() -> Tuple[float, float]:\n",
    "    x = sample(Uniform(-1, 1))\n",
    "    y = sample(Uniform(-1, 1))\n",
    "    d2 = x**2 + y**2\n",
    "    assume(d2 < 1)\n",
    "    return (x, y)\n",
    "with RejectionSampling(num_samples=1000):\n",
    "    dist: Empirical = infer(HardDisk) \n",
    "    x, y = zip(*dist.samples)\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning can be soft: `observe(Gaussian(d2, 0.1), o)` condition the law given observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftDisk() -> Tuple[float, float]:\n",
    "    x = sample(Uniform(-1, 1))\n",
    "    y = sample(Uniform(-1, 1))\n",
    "    d2 = x**2 + y**2\n",
    "    observe(Gaussian(d2, 0.1), 0.5)\n",
    "    return(x, y)\n",
    "\n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist: Categorical[Tuple[float, float]] = infer(SoftDisk)\n",
    "    w = dist.probs\n",
    "    x, y = list(zip(*dist.values))\n",
    "    plt.scatter(x, y, c=w**0.5, cmap='Reds', s=10)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copies of the result of sampling once a Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlipSum(n: int, d) -> int:\n",
    "    x = sample(d, \"bern\")\n",
    "    sum = 0\n",
    "    for k in range(n):\n",
    "        sum += x\n",
    "    return sum\n",
    "\n",
    "with Enumeration():\n",
    "    dist: Categorical[float] = infer(FlipSum, 20, Bernoulli(0.2)) \n",
    "    print(dist.stats())\n",
    "    viz(dist)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bags of i.i.d copies of a Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RandomWalk(n: int, d) -> int:\n",
    "    s = 0\n",
    "    for k in range(n):\n",
    "        s += 0.5 - sample(d)\n",
    "    return s \n",
    "\n",
    "with ImportanceSampling(num_particles=100000):\n",
    "    ST: Categorical[float] = infer(RandomWalk, 20, Bernoulli(0.2))  \n",
    "    print(ST.stats())\n",
    "    viz(ST)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def model0(data):\n",
    "    m = sample(Gaussian(0.0, 3.0), name=\"a\")\n",
    "    b = sample(Gaussian(0.0, 3.0), name=\"b\")\n",
    "    f = lambda x: m*x +b\n",
    "    return f\n",
    "\n",
    "def model(data):\n",
    "    m = sample(Gaussian(0.0, 3.0), name=\"a\")\n",
    "    b = sample(Gaussian(0.0, 3.0), name=\"b\")\n",
    "    f = lambda x: m*x +b\n",
    "    for (x, y) in data:\n",
    "        observe(Gaussian(f(x), 0.5), y)\n",
    "    return f\n",
    "\n",
    "data = [(1.0, 2.5), (2.0, 3.8), (3.0, 4.5), (4.0, 6.2), (5.0, 8.0)]\n",
    "\n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist0: Categorical[Tuple[float,float]] = infer(model0, data)\n",
    "    dist: Categorical[Tuple[float,float]] = infer(model, data)\n",
    "    \n",
    "    for i in range(500):\n",
    "        x = np.linspace(0, 6, 2)\n",
    "        f = dist.sample()\n",
    "        f0 = dist0.sample()\n",
    "        plt.plot(x, f0(x), color='blue', alpha=0.1, zorder=0)\n",
    "        plt.plot(x, f(x), color='purple', alpha=0.1, zorder=0)\n",
    "    \n",
    "\n",
    "    x_obs = [obs[0] for obs in data]\n",
    "    y_obs =  [obs[1] for obs in data]\n",
    "\n",
    "    plt.scatter(x_obs, y_obs, color='red', zorder=1)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muppl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
